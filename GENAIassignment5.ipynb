{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f-gBG9p8lQ4e"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xIszFhYelXND"
      },
      "outputs": [],
      "source": [
        "urls = [\"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\",\n",
        "\n",
        "        \"https://www.gutenberg.org/cache/epub/158/pg158.txt\",\n",
        "\n",
        "        \"https://www.gutenberg.org/cache/epub/161/pg161.txt\"\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gBagZAE3lqCC"
      },
      "outputs": [],
      "source": [
        "pride_text = \"\"\n",
        "emma_text = \"\"\n",
        "sense_text = \"\"\n",
        "\n",
        "\n",
        "pride_text = urls[0]\n",
        "emma_text = urls[1]\n",
        "sense_text = urls[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iS25XABPmNiy"
      },
      "outputs": [],
      "source": [
        "# Pride and Prejudice text\n",
        "response = requests.get(pride_text)\n",
        "pride_text = response.text\n",
        "\n",
        "# Emma text\n",
        "response = requests.get(emma_text)\n",
        "emma_text = response.text\n",
        "\n",
        "# Sense and Sensibility text\n",
        "response = requests.get(sense_text)\n",
        "sense_text = response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HotDPYuFeIil"
      },
      "outputs": [],
      "source": [
        "# Pride and Prejudice - Text Clean Up\n",
        "pride_text=pride_text[35866:]\n",
        "pride_text=pride_text[:708210]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wEMcFlysgHyF"
      },
      "outputs": [],
      "source": [
        "# Emma - Text Clean Up\n",
        "emma_text=emma_text[1699:]\n",
        "emma_text=emma_text[:895997]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4-CLoixJkaUN"
      },
      "outputs": [],
      "source": [
        "# Sense and Sensibility - Text Clean Up\n",
        "sense_text=sense_text[1612:]\n",
        "sense_text=sense_text[:682514]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BuMV_kxFmnvf"
      },
      "outputs": [],
      "source": [
        "#combine all three texts into one variable\n",
        "all_text = \"\"\n",
        "\n",
        "all_text = pride_text + emma_text + sense_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0iAlpTUkm5ew"
      },
      "outputs": [],
      "source": [
        "# place all_text into a .txt file\n",
        "with open(\"combined_austen.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "  file.write(all_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nrQvvDjdvyHb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "file_path = '/content/combined_austen.txt'\n",
        "\n",
        "# Function to load the raw text from a file\n",
        "def load_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove anything in square brackets\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "\n",
        "    # Clean up extra newlines or spaces\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Remove spaces before punctuation\n",
        "    text = re.sub(r' \\.', '.', text)\n",
        "    text = re.sub(r' \\,', ',', text)\n",
        "    text = re.sub(r' \\?', '?', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# Split the text into chapters\n",
        "def split_into_chapters(text):\n",
        "    chapter_pattern = r'(CHAPTER [IVXLCDM]+[\\.\\s]?)|(\\bChapter \\d+\\b)'  # Match variations of chapter headings\n",
        "\n",
        "    # Split the text into chapters using the regex pattern\n",
        "    chapters = re.split(chapter_pattern, text)\n",
        "\n",
        "    # Filter out empty strings and clean up extra spaces, ignoring chapter headings\n",
        "    chapters = [chapter.strip() for chapter in chapters if chapter and not re.match(chapter_pattern, chapter.strip())]\n",
        "\n",
        "    return chapters\n",
        "\n",
        "# Concatenate all chapters\n",
        "def format_chapters(chapters):\n",
        "    return ''.join(chapters)\n",
        "\n",
        "# Function to save the updated text back to a file\n",
        "def save_text_to_file(cleaned_text, output_file):\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "# Main function to process and format the text\n",
        "def process_text(input_file, output_file):\n",
        "    # Load the raw text\n",
        "    raw_text = load_text(input_file)\n",
        "\n",
        "    # Clean the text\n",
        "    cleaned_text = clean_text(raw_text)\n",
        "\n",
        "    # Step 3: Split the text into chapters\n",
        "    chapters = split_into_chapters(cleaned_text)\n",
        "\n",
        "    # Step 4: Format the chapters with appropriate headers or formatting\n",
        "    formatted_text = format_chapters(chapters)\n",
        "\n",
        "    # Step 5: Save the cleaned and formatted text\n",
        "    save_text_to_file(formatted_text, output_file)\n",
        "\n",
        "# Example usage\n",
        "input_file = '/content/combined_austen.txt'  # Path to your raw text file\n",
        "output_file = '/content/formatted_austen.txt'  # Path where you want to save the cleaned text\n",
        "\n",
        "process_text(input_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1IX0C23yU4L",
        "outputId": "7044775c-68db-46a8-ad91-634b7a15912d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapter I.] It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters. “My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” Mr.\n"
          ]
        }
      ],
      "source": [
        "# Function to read the formatted text from a file\n",
        "def load_processed_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "# Load the formatted text into a variable\n",
        "formatted_text = load_processed_text('/content/formatted_austen.txt')\n",
        "\n",
        "# Check the first 500 characters to make sure it's loaded correctly\n",
        "print(formatted_text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MItaTkfpo-Mn"
      },
      "outputs": [],
      "source": [
        "# Pad the punctuation, to treat them as separate 'words'\n",
        "def pad_punctuation(s):\n",
        "    s = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", s)\n",
        "    s = re.sub(\" +\", \" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "text_data = pad_punctuation(formatted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do_z6VudzAGR",
        "outputId": "419576e4-6e25-45f3-f349-57476e7617ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')  # Download sentence tokenizer\n",
        "\n",
        "# Split formatted_text into sentences\n",
        "text_data = nltk.sent_tokenize(text_data)  # Tokenize by sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "MAX_LEN = 200"
      ],
      "metadata": {
        "id": "CQ9E2np-vboZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-sagpZnmpLjQ"
      },
      "outputs": [],
      "source": [
        "#create text dataset from raw text\n",
        "text_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(text_data)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(1000)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MOzcoUT0pUwh"
      },
      "outputs": [],
      "source": [
        "#create vectorization layer\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    #max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_LEN + 1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4O4yGcvLpXL4"
      },
      "outputs": [],
      "source": [
        "# Adapt the layer to the training set\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NtNp_rbzYVE",
        "outputId": "849ae165-3e14-4231-9e8e-dab3b33c3ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 13207\n",
            "Sample vocabulary: ['', '[UNK]', ',', '.', 'the', 'to', 'of', 'and', 'her', 'a']\n"
          ]
        }
      ],
      "source": [
        "# Print the size of the vocabulary and the first 10 tokens\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "print(f\"Sample vocabulary: {vocab[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_V4uK8mItCgr"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OApradgqpZQB",
        "outputId": "e3e0f65a-ef6a-4cef-bef7-370a5e76fbe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: \n",
            "1: [UNK]\n",
            "2: ,\n",
            "3: .\n",
            "4: the\n",
            "5: to\n",
            "6: of\n",
            "7: and\n",
            "8: her\n",
            "9: a\n"
          ]
        }
      ],
      "source": [
        "# Display some token:word mappings\n",
        "for i, word in enumerate(vocab[:10]):\n",
        "    print(f\"{i}: {word}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7mbmwi4bp5iw"
      },
      "outputs": [],
      "source": [
        "# Create the training set text and the same text shifted by one word\n",
        "def prepare_inputs(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p0OOJDGLqFKw"
      },
      "outputs": [],
      "source": [
        "# Create a TextGenerator checkpoint\n",
        "class TextGenerator(callbacks.Callback):\n",
        "    def __init__(self, index_to_word, top_k=10):\n",
        "        self.index_to_word = index_to_word\n",
        "        self.word_to_index = {\n",
        "            word: index for index, word in enumerate(index_to_word)\n",
        "        }  # <1>\n",
        "\n",
        "    def sample_from(self, probs, temperature):  # <2>\n",
        "        probs = probs ** (1 / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(len(probs), p=probs), probs\n",
        "\n",
        "    def generate(self, start_prompt, max_tokens, temperature):\n",
        "        start_tokens = [\n",
        "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
        "        ]  # <3>\n",
        "        sample_token = None\n",
        "        info = []\n",
        "        while len(start_tokens) < max_tokens and sample_token != 0:  # <4>\n",
        "            x = np.array([start_tokens])\n",
        "            y = self.model.predict(x, verbose=0)  # <5>\n",
        "            sample_token, probs = self.sample_from(y[0][-1], temperature)  # <6>\n",
        "            info.append({\"prompt\": start_prompt, \"word_probs\": probs})\n",
        "            start_tokens.append(sample_token)  # <7>\n",
        "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
        "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
        "        return info\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.generate(\"Text Generated = \", max_tokens=100, temperature=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4DyOn96DqHlO"
      },
      "outputs": [],
      "source": [
        "# Tokenize starting prompt\n",
        "text_generator = TextGenerator(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 1: one layer, 128 N_UNITS**"
      ],
      "metadata": {
        "id": "47TG6K9A1N-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gAXOgwTpQUR"
      },
      "outputs": [],
      "source": [
        "#VOCAB_SIZE = 10000\n",
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "N_UNITS = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "SEED = 42\n",
        "LOAD_MODEL = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "ddVfGiX3p92E",
        "outputId": "920851df-ed74-43ab-b806-092162eba05c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │       \u001b[38;5;34m1,320,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m117,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13207\u001b[0m)         │       \u001b[38;5;34m1,703,703\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13207</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,703,703</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,141,651\u001b[0m (11.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,141,651</span> (11.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,141,651\u001b[0m (11.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,141,651</span> (11.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# train with one layer\n",
        "\n",
        "inputs = layers.Input(shape=(None,), dtype=\"int32\")\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x = layers.LSTM(N_UNITS, return_sequences=True)(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "lstm = models.Model(inputs, outputs)\n",
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzzvJgbMqC4A"
      },
      "outputs": [],
      "source": [
        "loss_fn = losses.SparseCategoricalCrossentropy()\n",
        "lstm.compile(\"adam\", loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK4PLhd6rUXj",
        "outputId": "c5484194-8b66-4f1d-cb6b-b130ddb6a3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.7694\n",
            "generated text:\n",
            "Text Generated =  inmates subscribe saying of and , sorry . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 56ms/step - loss: 1.7682\n",
            "Epoch 2/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5718\n",
            "generated text:\n",
            "Text Generated =  place , within not ! \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.5717\n",
            "Epoch 3/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5262\n",
            "generated text:\n",
            "Text Generated =  argued for it . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.5262\n",
            "Epoch 4/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4969\n",
            "generated text:\n",
            "Text Generated =  head up ; and she had been in your friends . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.4969\n",
            "Epoch 5/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4719\n",
            "generated text:\n",
            "Text Generated =  affected well , “well . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 58ms/step - loss: 0.4719\n",
            "Epoch 6/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4576\n",
            "generated text:\n",
            "Text Generated =  that resentment is carrying against her ; he would be happy ; her feelings in fame for her . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 60ms/step - loss: 0.4576\n",
            "Epoch 7/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4443\n",
            "generated text:\n",
            "Text Generated =  exactly once ? \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.4443\n",
            "Epoch 8/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4347\n",
            "generated text:\n",
            "Text Generated =  good luck . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 58ms/step - loss: 0.4347\n",
            "Epoch 9/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4239\n",
            "generated text:\n",
            "Text Generated =  gave , thoroughly success . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.4239\n",
            "Epoch 10/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4163\n",
            "generated text:\n",
            "Text Generated =  to be with it alone , there was the ear of detection , she could not all have an easy temple , nor confined which she received her mistress of the opportunity of emotion ; till , with obsequious them all the - “my knowledge of other years himself , which all every young lady point offered to their house , it might be able to property back . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.4163\n",
            "Epoch 11/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4079\n",
            "generated text:\n",
            "Text Generated =  with them were in such a turn she took place in the narrative of their visitor passed on , so far to her uncle and affability which could look forward answer in life his acquaintance on it . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 60ms/step - loss: 0.4079\n",
            "Epoch 12/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4000\n",
            "generated text:\n",
            "Text Generated =  captivating countries , and they must see mrs . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.4000\n",
            "Epoch 13/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4022\n",
            "generated text:\n",
            "Text Generated =  . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.4022\n",
            "Epoch 14/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3966\n",
            "generated text:\n",
            "Text Generated =  within it as finding him . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 59ms/step - loss: 0.3966\n",
            "Epoch 15/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3813\n",
            "generated text:\n",
            "Text Generated =  compliment , very sudden , as disposition , she was perfectly impatient for it , and her own knowledge herself intended to appear that it was easy ; but which he intends to deserve the question of lady catherine de bourgh , her eyes were cold , and gentle audibly , and she wondered in praise of it some men , she had visiting to be here considered your father—or tomorrow . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 64ms/step - loss: 0.3813\n",
            "Epoch 16/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3778\n",
            "generated text:\n",
            "Text Generated =  to appear in her own ; she will indulge me for me again ; for , - twenty - morning , good and fifty pounds ! \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 60ms/step - loss: 0.3778\n",
            "Epoch 17/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3643\n",
            "generated text:\n",
            "Text Generated =  by a visit immediately spent up , or such an unnecessary glowing spot has made it now after maple grove ! \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 60ms/step - loss: 0.3643\n",
            "Epoch 18/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3748\n",
            "generated text:\n",
            "Text Generated =  in that always go along , and the case . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 60ms/step - loss: 0.3748\n",
            "Epoch 19/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3686\n",
            "generated text:\n",
            "Text Generated =  , on her release , any thing could have been happy . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 60ms/step - loss: 0.3686\n",
            "Epoch 20/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3653\n",
            "generated text:\n",
            "Text Generated =  , which cast her home now had been wholly away from emma . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 59ms/step - loss: 0.3653\n",
            "Epoch 21/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3489\n",
            "generated text:\n",
            "Text Generated =  . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.3489\n",
            "Epoch 22/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3505\n",
            "generated text:\n",
            "Text Generated =  to be deceived as to be the steps : but marianne stopped to her . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 59ms/step - loss: 0.3505\n",
            "Epoch 23/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3460\n",
            "generated text:\n",
            "Text Generated =  hopes , however ; but every acre for upright countenance and perplexing emotions , so well , all in all opposition , and said , with a smile , had suggested every assurance of the latter whose urgent noisy appearance of blacken affection however ever : —caution for the character of hearing any observation of her ideas of marianne’s security for their attentions . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.3460\n",
            "Epoch 24/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3436\n",
            "generated text:\n",
            "Text Generated =  by his own claims , that with a manners that there is reason to oppose the language of it , from all mr . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 60ms/step - loss: 0.3436\n",
            "Epoch 25/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3412\n",
            "generated text:\n",
            "Text Generated =  by seeing him to the altar from the very second page . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 59ms/step - loss: 0.3412\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f6812c1c280>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "lstm.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[text_generator],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print probabilities of next token\n",
        "def print_probs(info, vocab, top_k=5):\n",
        "    for i in info:\n",
        "        print(f\"\\nPROMPT: {i['prompt']}\")\n",
        "        word_probs = i[\"word_probs\"]\n",
        "        p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
        "        i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
        "        for p, i in zip(p_sorted, i_sorted):\n",
        "            print(f\"{vocab[i]}:   \\t{np.round(100*p,2)}%\")\n",
        "        print(\"--------\\n\")"
      ],
      "metadata": {
        "id": "2OQNvqCR7aZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"Emma saw that\", max_tokens=25, temperature=0.25\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEd0rpc17d5P",
        "outputId": "39ae3852-d266-48b1-c85f-6ed231d82127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "Emma saw that he had been in town , and was the time of her own , and the most natural and frozen maid .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_probs(info, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCqua8n67g8V",
        "outputId": "9a48109a-5365-4c68-8747-6872f0757c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PROMPT: Emma saw that\n",
            "he:   \t79.85%\n",
            "she:   \t15.4%\n",
            "the:   \t2.35%\n",
            "there:   \t0.85%\n",
            "it:   \t0.73%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he\n",
            "had:   \t92.2%\n",
            "was:   \t7.49%\n",
            "should:   \t0.27%\n",
            "would:   \t0.04%\n",
            "might:   \t0.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had\n",
            "been:   \t99.34%\n",
            "not:   \t0.63%\n",
            "a:   \t0.02%\n",
            "never:   \t0.0%\n",
            "done:   \t0.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been\n",
            "in:   \t53.06%\n",
            "a:   \t22.4%\n",
            "the:   \t9.82%\n",
            "so:   \t9.22%\n",
            "at:   \t4.33%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in\n",
            "the:   \t57.13%\n",
            "town:   \t38.65%\n",
            "love:   \t2.26%\n",
            "a:   \t1.42%\n",
            "london:   \t0.53%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town\n",
            ",:   \t87.74%\n",
            ";:   \t8.92%\n",
            ".:   \t3.21%\n",
            "before:   \t0.04%\n",
            "to:   \t0.02%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town ,\n",
            "and:   \t99.95%\n",
            "but:   \t0.02%\n",
            "or:   \t0.02%\n",
            "for:   \t0.0%\n",
            "was:   \t0.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and\n",
            "the:   \t50.7%\n",
            "she:   \t28.64%\n",
            "was:   \t7.6%\n",
            "had:   \t3.91%\n",
            "to:   \t2.07%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was\n",
            "a:   \t47.31%\n",
            "the:   \t14.81%\n",
            "now:   \t11.9%\n",
            "not:   \t10.79%\n",
            "very:   \t10.41%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the\n",
            "very:   \t35.64%\n",
            "time:   \t31.92%\n",
            "most:   \t20.69%\n",
            "same:   \t6.82%\n",
            "smallest:   \t1.81%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time\n",
            "of:   \t99.99%\n",
            "with:   \t0.01%\n",
            "for:   \t0.0%\n",
            "to:   \t0.0%\n",
            "in:   \t0.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of\n",
            "her:   \t65.29%\n",
            "the:   \t23.23%\n",
            "a:   \t6.82%\n",
            "his:   \t4.31%\n",
            "all:   \t0.13%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her\n",
            "own:   \t99.93%\n",
            "daughters:   \t0.02%\n",
            "brother:   \t0.01%\n",
            "sister:   \t0.01%\n",
            "favourite:   \t0.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own\n",
            ",:   \t97.4%\n",
            ".:   \t0.98%\n",
            "family:   \t0.65%\n",
            "children:   \t0.51%\n",
            ";:   \t0.22%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own ,\n",
            "and:   \t99.95%\n",
            "than:   \t0.03%\n",
            "or:   \t0.01%\n",
            "but:   \t0.01%\n",
            "which:   \t0.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own , and\n",
            "the:   \t80.64%\n",
            "a:   \t6.49%\n",
            "her:   \t3.4%\n",
            "all:   \t2.78%\n",
            "that:   \t2.32%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own , and the\n",
            "most:   \t54.15%\n",
            "very:   \t33.47%\n",
            "same:   \t2.6%\n",
            "case:   \t1.33%\n",
            "greatest:   \t1.28%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own , and the most\n",
            "natural:   \t94.14%\n",
            "rapacious:   \t1.75%\n",
            "solicitous:   \t1.64%\n",
            "important:   \t1.16%\n",
            "affectionate:   \t0.58%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own , and the most natural\n",
            "and:   \t99.3%\n",
            "connection:   \t0.37%\n",
            "affection:   \t0.1%\n",
            "-:   \t0.07%\n",
            "sort:   \t0.04%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own , and the most natural and\n",
            "frozen:   \t63.63%\n",
            "forgiving:   \t15.25%\n",
            "commandingly:   \t6.18%\n",
            "social:   \t4.78%\n",
            "agreeable:   \t3.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own , and the most natural and frozen\n",
            "maid:   \t100.0%\n",
            "eyes:   \t0.0%\n",
            "wind:   \t0.0%\n",
            "figure:   \t0.0%\n",
            "benevolence:   \t0.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: Emma saw that he had been in town , and was the time of her own , and the most natural and frozen maid\n",
            ".:   \t99.75%\n",
            ",:   \t0.24%\n",
            ";:   \t0.01%\n",
            "!:   \t0.0%\n",
            "::   \t0.0%\n",
            "--------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"Pride had taken it all\", max_tokens=50, temperature=0.50\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdNcD9ie7tZR",
        "outputId": "3c77bd34-fbba-4600-82fc-d96c68d06bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "Pride had taken it all over in her power to be done . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"How is it that\", max_tokens=50, temperature=1.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVQZ83EO8Rn9",
        "outputId": "9c8fb3f0-9df7-4c22-d23e-4a1ae5c4b5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "How is it that i have not occurred to him ? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 2: two layers + 128 N_UNITS**"
      ],
      "metadata": {
        "id": "-gQL75he1skt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VOCAB_SIZE = 10000\n",
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "N_UNITS = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "SEED = 42\n",
        "LOAD_MODEL = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25"
      ],
      "metadata": {
        "id": "TiFzAC5P13xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "Lm8khXshMtAR",
        "outputId": "873433cc-e6d3-4fb4-ce67-1143ad9ef394"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │       \u001b[38;5;34m1,320,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m117,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13207\u001b[0m)         │       \u001b[38;5;34m1,703,703\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13207</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,703,703</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,273,235\u001b[0m (12.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,273,235</span> (12.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,273,235\u001b[0m (12.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,273,235</span> (12.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#train with two layers\n",
        "inputs = layers.Input(shape=(None,), dtype=\"int32\")\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x = layers.LSTM(N_UNITS, return_sequences=True)(x)\n",
        "x = layers.LSTM(N_UNITS)(x)\n",
        "\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "lstm = models.Model(inputs, outputs)\n",
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = losses.SparseCategoricalCrossentropy()\n",
        "lstm.compile(\"adam\", loss_fn)\n",
        "\n",
        "lstm.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[text_generator],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8a2LZT72CUk",
        "outputId": "257f3386-3cab-4f99-c692-64cf5aa26eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.8085\n",
            "generated text:\n",
            "Text Generated =  and from _ to to , the has at say ; communication borne it the not shall the to must to was of good all aye own blunders insipidity i to had better the declare—and eldest . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 67ms/step - loss: 1.8072\n",
            "Epoch 2/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5717\n",
            "generated text:\n",
            "Text Generated =  and and take , you was held raise him of his claims . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - loss: 0.5717\n",
            "Epoch 3/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5188\n",
            "generated text:\n",
            "Text Generated =  company , as the curiosity could he had always foolishly indifference to give one sinking ; that he had without that buried to quite what hurt the twenty farewell me , i not off to discovered , and _ the natural clear _ ever make nobody well it ; to take a it to be why what it cordially what all her virtue at this distress friends , at miss turn to not be the subject , perhaps did are them—for information to making the world , it had little never always begin to much to marry\n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 72ms/step - loss: 0.5188\n",
            "Epoch 4/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4969\n",
            "generated text:\n",
            "Text Generated =  him refuse away , and though this - with elinor was glad for that examining her sister’s acquaintance robert , below under any an eyelashes for their having little struggle ; and little of the best room to her conviction of her work . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 68ms/step - loss: 0.4968\n",
            "Epoch 5/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4884\n",
            "generated text:\n",
            "Text Generated =  in this pounds was in wishing . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - loss: 0.4884\n",
            "Epoch 6/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4638\n",
            "generated text:\n",
            "Text Generated =  to have then many hundred a _ circumstances cause , yet much going to the deliverance of isabella’s fire . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 66ms/step - loss: 0.4638\n",
            "Epoch 7/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4486\n",
            "generated text:\n",
            "Text Generated =  him—and but a sheet of tea ought , it began the hours—and , as very obliged of no twice like ever . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.4486\n",
            "Epoch 8/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4387\n",
            "generated text:\n",
            "Text Generated =  to last person ; and this fairfax _ never , i must be other ; in stout mildness to be beyond circumstances . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 67ms/step - loss: 0.4387\n",
            "Epoch 9/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4222\n",
            "generated text:\n",
            "Text Generated =  it to do not since she is not at service to dance . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 66ms/step - loss: 0.4222\n",
            "Epoch 10/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4083\n",
            "generated text:\n",
            "Text Generated =  here exactly fast . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - loss: 0.4083\n",
            "Epoch 11/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4032\n",
            "generated text:\n",
            "Text Generated =  or rate . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 66ms/step - loss: 0.4032\n",
            "Epoch 12/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4057\n",
            "generated text:\n",
            "Text Generated =  , usual , two years ago , for your own temper , not to have thirteen . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.4057\n",
            "Epoch 13/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4033\n",
            "generated text:\n",
            "Text Generated =  to give your arms , the generosity of what she had been depreciating . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.4033\n",
            "Epoch 14/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3909\n",
            "generated text:\n",
            "Text Generated =  to her , to try her own hand , and no miss eat enjoyment . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.3909\n",
            "Epoch 15/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3902\n",
            "generated text:\n",
            "Text Generated =  his admiration on her side . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.3902\n",
            "Epoch 16/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3774\n",
            "generated text:\n",
            "Text Generated =  , “there can not honour—i not one day through this impertinent gilberts , and the masters of the most houses whom you need not take orders , that it cares to _ them _ ; and they have been so unwelcome obliged to mrs . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 69ms/step - loss: 0.3774\n",
            "Epoch 17/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3705\n",
            "generated text:\n",
            "Text Generated =  amongst the door cut away each , was perhaps at the same time , a speech , which , did rise to attend out , and added the inquiry conveying directly unequal and contentment ! \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 68ms/step - loss: 0.3705\n",
            "Epoch 18/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3643\n",
            "generated text:\n",
            "Text Generated =  to be , without encouragement for mrs . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.3643\n",
            "Epoch 19/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3582\n",
            "generated text:\n",
            "Text Generated =  voluntarily intending to shew farther advantage , emma but having now much over his intellectual exemption in the spot officious importance to establishment to cease ; but it was not that ever expressed for view that day settled to only an inn - weston ; she had never been known to her daughters’ arm before , as wholly as charlotte had done , if her brother and beauty had been always reprehensible . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 71ms/step - loss: 0.3582\n",
            "Epoch 20/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3554\n",
            "generated text:\n",
            "Text Generated =  at once out and detain me in the truer family , and yet she is convinced to every other method about my matters . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - loss: 0.3554\n",
            "Epoch 21/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3512\n",
            "generated text:\n",
            "Text Generated =  during the first time from her father . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.3512\n",
            "Epoch 22/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3428\n",
            "generated text:\n",
            "Text Generated =  his eyes to the ladies nor long ; and to bespeak her visitors on our poor , miss brandon pleased that they would not give to herself favour , when she stopped to take leave , and neither proud nor information . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 68ms/step - loss: 0.3428\n",
            "Epoch 23/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3394\n",
            "generated text:\n",
            "Text Generated =  , after every school , in the evening , one , if not quite convinced that there was to be sorry ! \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 67ms/step - loss: 0.3394\n",
            "Epoch 24/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3346\n",
            "generated text:\n",
            "Text Generated =  perpetually uninterruptedly ; and though in her ladyship’s ceasing for seeing it , they had not been tedious and small , but he had but been staying more resolutely over with an proper resolution , but yet the severe news she had secured . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 68ms/step - loss: 0.3346\n",
            "Epoch 25/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3265\n",
            "generated text:\n",
            "Text Generated =  on the world . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 66ms/step - loss: 0.3265\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ef9141165c0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"In a situation that\", max_tokens=25, temperature=1.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es2uFtMIFCes",
        "outputId": "ffbb5f11-6bdc-41ea-e47d-f3f544b3f98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "In a situation that painful solemnity could be in beauty . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"In a situation that\", max_tokens=25, temperature=0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9zkpWyoFM5j",
        "outputId": "4d606a4d-0054-4132-8e35-079feae99a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "In a situation that is so much preferable to his own . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"Jane had given\", max_tokens=25, temperature=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0eWXuILGfih",
        "outputId": "81969657-83ea-483e-f8e5-d8f80c34081a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "Jane had given her pleasure in her own mind , she was not in the least to say that she was not to be supposed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"Mr. Darcy wanted\", max_tokens=25, temperature=1.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aT8xlDT2IRF",
        "outputId": "6ffe9865-f52f-4ee9-88da-a7358aa5ba67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "Mr. Darcy wanted to render their excuse , that my mind left no further amends to own the distress of the feelings and while he\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 3: one layer and 256 N_UNITS**"
      ],
      "metadata": {
        "id": "Z66btoC62Ctx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv-1aTY-Wekc"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "N_UNITS = 256\n",
        "VALIDATION_SPLIT = 0.2\n",
        "SEED = 42\n",
        "LOAD_MODEL = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUdHfsW7WQmV",
        "outputId": "e1df9c55-59e6-4bdd-f6b9-539741d9626c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.7767\n",
            "generated text:\n",
            "Text Generated =  cow approbation without sat together to ? \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 55ms/step - loss: 1.7755\n",
            "Epoch 2/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5683\n",
            "generated text:\n",
            "Text Generated =  invalids “never of nothing it as ridicule means felt . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 56ms/step - loss: 0.5683\n",
            "Epoch 3/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.5246\n",
            "generated text:\n",
            "Text Generated =  throats to on the body and make , i look with common dear else . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 58ms/step - loss: 0.5246\n",
            "Epoch 4/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.5020\n",
            "generated text:\n",
            "Text Generated =  giving delaford and exceeded him her place till no day . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.5020\n",
            "Epoch 5/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4629\n",
            "generated text:\n",
            "Text Generated =  i hope . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.4629\n",
            "Epoch 6/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4688\n",
            "generated text:\n",
            "Text Generated =  sorry—extremely hours , the house was a visit in emma , “do not comprehend how much of him . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 59ms/step - loss: 0.4688\n",
            "Epoch 7/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4491\n",
            "generated text:\n",
            "Text Generated =  was fixed , lucas and kitty . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 58ms/step - loss: 0.4491\n",
            "Epoch 8/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4388\n",
            "generated text:\n",
            "Text Generated =  as she could have even done . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.4388\n",
            "Epoch 9/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4266\n",
            "generated text:\n",
            "Text Generated =  , if he understood the coming where there was not completely still , he spoke with an for his situation who was harmless lastingly attempted . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.4266\n",
            "Epoch 10/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4161\n",
            "generated text:\n",
            "Text Generated =  a lower ; and he than her admiration of ireland and maintained the world was . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.4161\n",
            "Epoch 11/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4035\n",
            "generated text:\n",
            "Text Generated =  , indeed . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.4035\n",
            "Epoch 12/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3975\n",
            "generated text:\n",
            "Text Generated =  ! \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 56ms/step - loss: 0.3976\n",
            "Epoch 13/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3955\n",
            "generated text:\n",
            "Text Generated =  out” height from an unexpensively ruins . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.3955\n",
            "Epoch 14/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3931\n",
            "generated text:\n",
            "Text Generated =  , i shall have his dependence . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 57ms/step - loss: 0.3931\n",
            "Epoch 15/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3743\n",
            "generated text:\n",
            "Text Generated =  it eluded little years of _ that next morning in her daughter and lucy smith , to slight pain . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 58ms/step - loss: 0.3744\n",
            "Epoch 16/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3782\n",
            "generated text:\n",
            "Text Generated =  than a readiness in his sex , being rather over the evening and three thousand pounds . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.3782\n",
            "Epoch 17/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3756\n",
            "generated text:\n",
            "Text Generated =  the next morning , marianne , to see what miss bates . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.3756\n",
            "Epoch 18/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3610\n",
            "generated text:\n",
            "Text Generated =  , ’ said his name your aunt in the same description of my point . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 58ms/step - loss: 0.3610\n",
            "Epoch 19/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3657\n",
            "generated text:\n",
            "Text Generated =  ( prejudiced when he came . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.3657\n",
            "Epoch 20/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3573\n",
            "generated text:\n",
            "Text Generated =  by willoughby , and as confident of her regrets . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.3573\n",
            "Epoch 21/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3508\n",
            "generated text:\n",
            "Text Generated =  as the friend , requested to see such a companion that she might be heard in perfect . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.3508\n",
            "Epoch 22/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3503\n",
            "generated text:\n",
            "Text Generated =  pleasure . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.3503\n",
            "Epoch 23/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3463\n",
            "generated text:\n",
            "Text Generated =  at me often . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 58ms/step - loss: 0.3463\n",
            "Epoch 24/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3367\n",
            "generated text:\n",
            "Text Generated =  and immovable unreserve ; it would be the excellent charge of her . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 58ms/step - loss: 0.3367\n",
            "Epoch 25/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3387\n",
            "generated text:\n",
            "Text Generated =  as her son , how delighted it was unavoidable . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.3387\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7936b9141f00>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#train with N_UNITS = 256 and one layer (trained on GPU)\n",
        "inputs = layers.Input(shape=(None,), dtype=\"int32\")\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x = layers.LSTM(N_UNITS, return_sequences=True)(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "lstm = models.Model(inputs, outputs)\n",
        "\n",
        "loss_fn = losses.SparseCategoricalCrossentropy()\n",
        "lstm.compile(\"adam\", loss_fn)\n",
        "\n",
        "lstm.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[text_generator],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSFGUTvoJ4AU",
        "outputId": "5300644c-d44d-49f2-91ef-f5db9888110e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "generated text:\n",
            "I was certain that it was impossible for sir john there . \n",
            "\n"
          ]
        }
      ],
      "source": [
        "info = text_generator.generate(\n",
        "    \"I was certain that\", max_tokens=25, temperature=1.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk5vulDJKgBL",
        "outputId": "b4398e7e-9e78-4751-ffc7-c44ea23d503b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "PROMPT: I was certain that\n",
            "he:   \t26.49%\n",
            "she:   \t12.5%\n",
            "i:   \t6.77%\n",
            "it:   \t5.58%\n",
            "they:   \t4.8%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it\n",
            "was:   \t41.62%\n",
            "would:   \t11.63%\n",
            "should:   \t9.38%\n",
            "is:   \t5.02%\n",
            "had:   \t4.57%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was\n",
            "not:   \t21.06%\n",
            "to:   \t5.11%\n",
            ".:   \t3.42%\n",
            "in:   \t2.8%\n",
            "a:   \t2.54%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was impossible\n",
            "for:   \t29.89%\n",
            "to:   \t23.38%\n",
            ".:   \t22.63%\n",
            ";:   \t8.27%\n",
            "that:   \t6.19%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was impossible for\n",
            "it:   \t10.16%\n",
            "him:   \t8.97%\n",
            "the:   \t8.91%\n",
            "her:   \t6.85%\n",
            "mr:   \t6.72%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was impossible for sir\n",
            "john:   \t40.0%\n",
            "william:   \t24.25%\n",
            "john’s:   \t10.36%\n",
            ".:   \t5.23%\n",
            ",:   \t4.94%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was impossible for sir john\n",
            "and:   \t21.44%\n",
            ".:   \t16.38%\n",
            ",:   \t12.45%\n",
            ";:   \t7.07%\n",
            "de:   \t3.46%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was impossible for sir john there\n",
            "was:   \t27.77%\n",
            ",:   \t17.49%\n",
            ".:   \t7.61%\n",
            ";:   \t7.55%\n",
            "would:   \t7.2%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was impossible for sir john there .\n",
            ":   \t99.95%\n",
            "):   \t0.03%\n",
            "and:   \t0.01%\n",
            "]:   \t0.0%\n",
            "on:   \t0.0%\n",
            "--------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_probs(info, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCoEOH-xLB1h",
        "outputId": "c02333ed-8691-4799-e33d-a8343b2f756e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "generated text:\n",
            "I was certain that it was not so . \n",
            "\n"
          ]
        }
      ],
      "source": [
        "info = text_generator.generate(\n",
        "    \"I was certain that\", max_tokens=25, temperature=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO3908tMLGBD",
        "outputId": "6e305503-c8d5-4bbe-bf9f-53eae58afde0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "PROMPT: I was certain that\n",
            "he:   \t69.85%\n",
            "she:   \t15.55%\n",
            "i:   \t4.57%\n",
            "it:   \t3.1%\n",
            "they:   \t2.3%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it\n",
            "was:   \t84.34%\n",
            "would:   \t6.59%\n",
            "should:   \t4.28%\n",
            "is:   \t1.23%\n",
            "had:   \t1.02%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was\n",
            "not:   \t82.52%\n",
            "to:   \t4.85%\n",
            ".:   \t2.18%\n",
            "in:   \t1.46%\n",
            "a:   \t1.2%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was not\n",
            "in:   \t32.54%\n",
            "to:   \t32.22%\n",
            "so:   \t8.67%\n",
            "a:   \t3.83%\n",
            "at:   \t2.73%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was not so\n",
            "much:   \t47.02%\n",
            ",:   \t10.16%\n",
            "very:   \t8.58%\n",
            ";:   \t6.67%\n",
            ".:   \t6.59%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: I was certain that it was not so .\n",
            ":   \t100.0%\n",
            "):   \t0.0%\n",
            "and:   \t0.0%\n",
            "]:   \t0.0%\n",
            "on:   \t0.0%\n",
            "--------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_probs(info, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ABBW4wMLf1s",
        "outputId": "11520ca3-0fbc-4066-bc04-26f01f602a7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "generated text:\n",
            "Emma said that he was not in their conclusions . \n",
            "\n"
          ]
        }
      ],
      "source": [
        "info = text_generator.generate(\n",
        "      \"Emma said that\", max_tokens=50, temperature=1.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Weklll4DMY3q",
        "outputId": "84856d7e-ceef-47ff-8b2f-3f1936eb5756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "generated text:\n",
            "Emma said that he would not allow him to be the best of the gentleman . \n",
            "\n"
          ]
        }
      ],
      "source": [
        "info = text_generator.generate(\n",
        "      \"Emma said that\", max_tokens=50, temperature=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 4: two layers, 256 N_UNITS**"
      ],
      "metadata": {
        "id": "NNcbQqFngv9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "N_UNITS = 256\n",
        "VALIDATION_SPLIT = 0.2\n",
        "SEED = 42\n",
        "LOAD_MODEL = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25"
      ],
      "metadata": {
        "id": "IxlnIXeqg0aB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train with two layers\n",
        "inputs = layers.Input(shape=(None,), dtype=\"int32\")\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x = layers.LSTM(N_UNITS, return_sequences=True)(x)\n",
        "x = layers.LSTM(N_UNITS, return_sequences=True)(x)\n",
        "\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "lstm = models.Model(inputs, outputs)\n",
        "lstm.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "76IHYY9lg5-I",
        "outputId": "bbeabe43-564d-479e-9826-03b267c8f6ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │       \u001b[38;5;34m1,320,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m365,568\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m525,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13207\u001b[0m)         │       \u001b[38;5;34m3,394,199\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13207</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,394,199</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,605,779\u001b[0m (21.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,605,779</span> (21.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,605,779\u001b[0m (21.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,605,779</span> (21.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = losses.SparseCategoricalCrossentropy()\n",
        "lstm.compile(\"adam\", loss_fn)\n",
        "\n",
        "lstm.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[text_generator],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uV8cSUqg8ma",
        "outputId": "d7ec9f8d-e356-4b2a-91b3-ec267c1f9b2c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 1.3631\n",
            "generated text:\n",
            "Text Generated =  woodhouse but agitated her till ; ; know befall before and as know the gouldings the desirous . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 95ms/step - loss: 1.3623\n",
            "Epoch 2/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.5536\n",
            "generated text:\n",
            "Text Generated =  inquiries , harriet there send as it is down . represented \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - loss: 0.5535\n",
            "Epoch 3/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.4933\n",
            "generated text:\n",
            "Text Generated =  on his son , you are no persuaded , ” “we was my son very sentiments ? \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - loss: 0.4933\n",
            "Epoch 4/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.4612\n",
            "generated text:\n",
            "Text Generated =  farther , soon after these tears , under giving her catherine , and wonder to all the same extraordinary affliction of her plan was now too much . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - loss: 0.4612\n",
            "Epoch 5/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.4316\n",
            "generated text:\n",
            "Text Generated =  with their imprudence , and many partiality is he as he should have casements three ; by the cards a support they had lived that point as his sister and meanness which walking up him necessary to her not the instrument , when she comes even to pass into the most late friend , i do not know it would be displeased that is his own minutes . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - loss: 0.4316\n",
            "Epoch 6/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.4212\n",
            "generated text:\n",
            "Text Generated =  this evening is more than three in miss smith’s way . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 97ms/step - loss: 0.4212\n",
            "Epoch 7/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.4093\n",
            "generated text:\n",
            "Text Generated =  unhappy , or of a screen” hands , by the colonel of his arms had she received the conviction of requesting this answer , had been an rich opinions—they led to another being a great moonlight grace of mrs . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - loss: 0.4093\n",
            "Epoch 8/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3950\n",
            "generated text:\n",
            "Text Generated =  for nothing . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - loss: 0.3950\n",
            "Epoch 9/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.3839\n",
            "generated text:\n",
            "Text Generated =  . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - loss: 0.3840\n",
            "Epoch 10/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3821\n",
            "generated text:\n",
            "Text Generated =  either of his object to me . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - loss: 0.3821\n",
            "Epoch 11/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3658\n",
            "generated text:\n",
            "Text Generated =  for him to be true ; but it must be nothing justice to himself ; but mr . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - loss: 0.3658\n",
            "Epoch 12/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3556\n",
            "generated text:\n",
            "Text Generated =  this morning , and at longstaple , though all as eight years possessing ever or her fortune , harriet could be attended , every year ferrars of the living would hold to bake together at cleveland . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 100ms/step - loss: 0.3556\n",
            "Epoch 13/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3488\n",
            "generated text:\n",
            "Text Generated =  . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - loss: 0.3488\n",
            "Epoch 14/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3242\n",
            "generated text:\n",
            "Text Generated =  to speak , more gentle than mrs . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - loss: 0.3242\n",
            "Epoch 15/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3191\n",
            "generated text:\n",
            "Text Generated =  to write for her one evening , and told them that she had been bringing on her chair from edward’s safety . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - loss: 0.3191\n",
            "Epoch 16/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3140\n",
            "generated text:\n",
            "Text Generated =  either . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - loss: 0.3140\n",
            "Epoch 17/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2974\n",
            "generated text:\n",
            "Text Generated =  , but said , she stopt again to the instrument with an objects till the true remarks of her family as well as marianne , for the sake of them . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 100ms/step - loss: 0.2974\n",
            "Epoch 18/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2918\n",
            "generated text:\n",
            "Text Generated =  by the explanation of their fireside , and had been entirely so ill - neighbours as she could . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - loss: 0.2918\n",
            "Epoch 19/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2847\n",
            "generated text:\n",
            "Text Generated =  from willoughby , which he considered with her gallant companion ; . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - loss: 0.2847\n",
            "Epoch 20/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2838\n",
            "generated text:\n",
            "Text Generated =  mr . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - loss: 0.2838\n",
            "Epoch 21/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2653\n",
            "generated text:\n",
            "Text Generated =  by them . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - loss: 0.2654\n",
            "Epoch 22/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2586\n",
            "generated text:\n",
            "Text Generated =  , blushed . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - loss: 0.2586\n",
            "Epoch 23/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2573\n",
            "generated text:\n",
            "Text Generated =  from him about his arrival . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - loss: 0.2573\n",
            "Epoch 24/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2477\n",
            "generated text:\n",
            "Text Generated =  to refuse any other point . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - loss: 0.2477\n",
            "Epoch 25/25\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2384\n",
            "generated text:\n",
            "Text Generated =  to have such a delightful sense of frank churchill . \n",
            "\n",
            "\u001b[1m736/736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - loss: 0.2385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a5087ed7580>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "      \"Mr. Bingley was good-looking\", max_tokens=50, temperature=1.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79wRoJnHuOcK",
        "outputId": "f6a6ba87-0258-426a-8ae7-69eccabbfe84"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "Mr. Bingley was good-looking enough ; it was not mistaken so ; and did not give off the opportunity of saying to miss bennet , who considered the impression of some others , but by its uncertain situation , that they did not enjoy them with each melancholy . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "      \"He danced all the dances\", max_tokens=50, temperature=1.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "258xT7osudsM",
        "outputId": "21118902-3b1d-42eb-d039-c321dba69afd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "He danced every dance towards the table , when sir john went on , which must be just supported , and by supplying the sound of the meeting , were all to resist harriet’s happiness . \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}